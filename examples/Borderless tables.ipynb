{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29dd04b4",
   "metadata": {},
   "source": [
    "* Segmentation de la page\n",
    "* contours dans les segments\n",
    "  * Aligment\n",
    "  * Tracer des lignes entre les contours et traiter comme tableau classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f40de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage\n",
    "from img2table.document import Image\n",
    "from img2table.ocr import TesseractOCR\n",
    "from img2table.tables.processing.common import get_contours_cell, is_contained_cell, merge_contours\n",
    "from img2table.tables.processing.lines import detect_lines\n",
    "from img2table.tables.objects.cell import Cell\n",
    "from colordict import ColorDict\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26acef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "colors = ColorDict()\n",
    "\n",
    "def get_color():\n",
    "    idx = random.randint(0, len(colors) - 1)\n",
    "    return list(colors.values())[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b7082",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image(r\"C:\\Users\\xavca\\Pictures\\test_2.png\")\n",
    "ocr = TesseractOCR()\n",
    "ocr_df = ocr.of(img)\n",
    "dpi = 200\n",
    "\n",
    "img = list(img.images)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb20d8b",
   "metadata": {},
   "source": [
    "### Remove lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd201c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_lines, v_lines = detect_lines(image=img,\n",
    "                                rho=0.3,\n",
    "                                theta=np.pi / 180,\n",
    "                                threshold=10,\n",
    "                                minLinLength=dpi // 20,\n",
    "                                maxLineGap=dpi // 20,\n",
    "                                kernel_size=dpi // 10,\n",
    "                                ocr_df=ocr_df)\n",
    "lines = h_lines + v_lines\n",
    "\n",
    "img_no_lines = img.copy()\n",
    "for line in lines:\n",
    "    cv2.rectangle(img_no_lines, (line.x1, line.y1), (line.x2, line.y2), (255, 255, 255), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac7baf9",
   "metadata": {},
   "source": [
    "### Remove dark bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.GaussianBlur(img_no_lines, (3, 3), 0)\n",
    "_, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "dilation = cv2.dilate(thresh, (10, 10), iterations=3)\n",
    "contours, _ = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "largest_contour = Cell(x1=0, x2=0, y1=0, y2=0)\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    contour_cell = Cell(x, y, x + w, y + h)\n",
    "    \n",
    "    if contour_cell.width * contour_cell.height > largest_contour.width * largest_contour.height:\n",
    "        largest_contour = contour_cell\n",
    "        \n",
    "# Recreate image\n",
    "white_img = np.zeros(img.shape, dtype=np.uint8)\n",
    "white_img.fill(255)\n",
    "\n",
    "white_img[largest_contour.y1:largest_contour.y2, largest_contour.x1:largest_contour.x2] = img_no_lines[largest_contour.y1:largest_contour.y2, largest_contour.x1:largest_contour.x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69859161",
   "metadata": {},
   "outputs": [],
   "source": [
    "PILImage.fromarray(white_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf92391",
   "metadata": {},
   "source": [
    "### Image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46064f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_segments = get_contours_cell(img=white_img.copy(),\n",
    "                                 cell=Cell(x1=0, y1=0, x2=img.shape[1], y2=img.shape[0]),\n",
    "                                 margin=0,\n",
    "                                 blur_size=3,\n",
    "                                 kernel_size=dpi // 10,\n",
    "                                 merge_vertically=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img = cv2.cvtColor(white_img.copy(), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "for cnt in img_segments:\n",
    "    cv2.rectangle(display_img, (cnt.x1, cnt.y1), (cnt.x2, cnt.y2), get_color(), 3)\n",
    "PILImage.fromarray(display_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39030354",
   "metadata": {},
   "source": [
    "### Text segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_contours = get_contours_cell(img=white_img.copy(),\n",
    "                                  cell=Cell(x1=0, y1=0, x2=img.shape[1], y2=img.shape[0]),\n",
    "                                  margin=0,\n",
    "                                  blur_size=3,\n",
    "                                  kernel_size=dpi * 3 // 200,\n",
    "                                  merge_vertically=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82e94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img = cv2.cvtColor(white_img.copy(), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "for cnt in text_contours:\n",
    "    cv2.rectangle(display_img, (cnt.x1, cnt.y1), (cnt.x2, cnt.y2), get_color(), 3)\n",
    "PILImage.fromarray(display_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed3bad",
   "metadata": {},
   "source": [
    "### Assign text contours to specific segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec730cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_segments = {seg: [] for seg in img_segments}\n",
    "for cnt in text_contours:\n",
    "    # Find most likely segment\n",
    "    best_segment = sorted([seg for seg in img_segments if is_contained_cell(inner_cell=cnt, outer_cell=seg)],\n",
    "                          key=lambda s: s.width * s.height,\n",
    "                          reverse=True).pop(0)\n",
    "    dict_segments[best_segment].append(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da7dc5",
   "metadata": {},
   "source": [
    "### Manual clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb40f8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img = cv2.cvtColor(white_img.copy(), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "def left_aligned(cell_1, cell_2):\n",
    "    width = np.min([cell_1.width, cell_2.width])\n",
    "    return abs(cell_1.x1 - cell_2.x1) / width < 0.1\n",
    "\n",
    "def right_aligned(cell_1, cell_2):\n",
    "    width = np.min([cell_1.width, cell_2.width])\n",
    "    return abs(cell_1.x2 - cell_2.x2) / width < 0.1\n",
    "\n",
    "def center_aligned(cell_1, cell_2):\n",
    "    width = np.min([cell_1.width, cell_2.width])\n",
    "    return abs(cell_1.x1 + cell_1.x2 - cell_2.x1 - cell_2.x2) / 2 * width < 0.1\n",
    "\n",
    "def aligned_cells(cell_1, cell_2):\n",
    "    return left_aligned(cell_1, cell_2) or right_aligned(cell_1, cell_2) or center_aligned(cell_1, cell_2)\n",
    "\n",
    "\n",
    "width = img.shape[1]\n",
    "\n",
    "for segment in dict_segments.values():\n",
    "    cells = sorted(set(segment), key=lambda c: (c.y1, c.x1))\n",
    "    \n",
    "    clusters = list()\n",
    "    for i in range(len(cells)):\n",
    "        for j in range(i + 1, len(cells)):\n",
    "            aligned = aligned_cells(cells[i], cells[j])\n",
    "            # If cells are adjacent, find matching clusters\n",
    "            if aligned:\n",
    "                matching_clusters = [idx for idx, cl in enumerate(clusters) if {i, j}.intersection(cl)]\n",
    "                if matching_clusters:\n",
    "                    remaining_clusters = [cl for idx, cl in enumerate(clusters) if idx not in matching_clusters]\n",
    "                    new_cluster = {i, j}.union(*[cl for idx, cl in enumerate(clusters) if idx in matching_clusters])\n",
    "                    clusters = remaining_clusters + [new_cluster]\n",
    "                else:\n",
    "                    clusters.append({i, j})\n",
    "\n",
    "    clusters = [merge_contours(contours=[cells[idx] for idx in cl]) for cl in clusters]\n",
    "    \n",
    "    for clust in clusters:\n",
    "        color = get_color()\n",
    "        for cnt in clust:\n",
    "            cv2.rectangle(display_img, (cnt.x1, cnt.y1), (cnt.x2, cnt.y2), color, 3)\n",
    "\n",
    "PILImage.fromarray(display_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeeb64c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
